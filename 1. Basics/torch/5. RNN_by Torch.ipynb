{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 감정 분석\n",
    "**RNN 을 이용해 IMDB 데이터를 가지고 텍스트 감정분석.**\n",
    "\n",
    "이번 책에서 처음으로 접하는 텍스트 형태의 데이터셋인 IMDB 데이터셋은 50,000건의 영화 리뷰로 이루어져 있습니다.\n",
    "각 리뷰는 다수의 영어 문장들로 이루어져 있으며, 평점이 7점 이상의 긍정적인 영화 리뷰는 2로, 평점이 4점 이하인 부정적인 영화 리뷰는 1로 레이블링 되어 있습니다. 영화 리뷰 텍스트를 RNN 에 입력시켜 영화평의 전체 내용을 압축하고, 이렇게 압축된 리뷰가 긍정적인지 부정적인지 판단해주는 간단한 분류 모델을 만드는 것이 이번 프로젝트의 목표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cuda\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 10\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 기기로 학습합니다:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩중...\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩하기\n",
    "print(\"데이터 로딩중...\")\n",
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True) # 첫번째 차원 값이 batch_size가 되는 batch_first\n",
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n",
    "TEXT.build_vocab(trainset, min_freq=5) # 최소 5번 이상 등장한 단어만 사전에, 미만은 'unk'\n",
    "LABEL.build_vocab(trainset)\n",
    "\n",
    "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
    "trainset, valset = trainset.split(split_ratio=0.8)\n",
    "\n",
    "# batch 단위로 쪼개기\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False)\n",
    "\n",
    "\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2 # 긍/부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
     ]
    }
   ],
   "source": [
    "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
    "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        print(\"Building Basic GRU model...\")\n",
    "        self.n_layers = n_layers # 은닉 벡터의 개수\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim) # 사전의 단어수, 임베딩 단어의 차원 수\n",
    "        self.hidden_dim = hidden_dim # 은닉 벡터의 차원\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x): # 오버라이딩되면서 자동 실행\n",
    "        x = self.embed(x)\n",
    "        h_0 = self._init_state(batch_size=x.size(0))\n",
    "        x, _ = self.gru(x, h_0)  # [batch_size, 입력 x의 길이, hidden_dim]\n",
    "        h_t = x[:,-1,:]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환(1씩 빼기)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n",
      "BasicGRU(\n",
      "  (embed): Embedding(46159, 128)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (gru): GRU(128, 256, batch_first=True)\n",
      "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# 어떤 최적화 알고리즘을 쓸지 모를때는 Adam으로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[이폭: 1] 검증 오차: 0.69 | 검증 정확도:49.00\n",
      "[이폭: 2] 검증 오차: 0.69 | 검증 정확도:50.00\n",
      "[이폭: 3] 검증 오차: 0.69 | 검증 정확도:54.00\n",
      "[이폭: 4] 검증 오차: 0.70 | 검증 정확도:50.00\n",
      "[이폭: 5] 검증 오차: 0.40 | 검증 정확도:81.00\n",
      "[이폭: 6] 검증 오차: 0.33 | 검증 정확도:86.00\n",
      "[이폭: 7] 검증 오차: 0.35 | 검증 정확도:85.00\n",
      "[이폭: 8] 검증 오차: 0.36 | 검증 정확도:86.00\n",
      "[이폭: 9] 검증 오차: 0.38 | 검증 정확도:86.00\n",
      "[이폭: 10] 검증 오차: 0.41 | 검증 정확도:86.00\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
    "    \n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차:  0.31 | 테스트 정확도: 86.00\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iter)\n",
    "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq 기계번역\n",
    "- \"hello\"를 \"hola\"로 바꾸는 Mini Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 256  # 총 아스키 코드 개수\n",
    "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
    "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size) # 임베딩된 토큰의 차원값으로 설정\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size) \n",
    "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 인코더에 들어갈 입력\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1) # 차원 추가\n",
    "        # embedding = [seq_len, batch_size, embedding_size]\n",
    "        \n",
    "        # 인코더 (Encoder)\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
    "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
    "\n",
    "        # 디코더에 들어갈 입력\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = torch.LongTensor([0]) # 문장시작을 알리기 위한 '0'\n",
    "        \n",
    "        # 디코더 (Decoder)\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(targets.size()[0]):\n",
    "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            projection = self.project(decoder_output) # 디코더의 출력값으로 다음 글자 예측\n",
    "            outputs.append(projection)\n",
    "            \n",
    "            #티처 포싱(Teacher Forcing) 사용\n",
    "            decoder_input = torch.LongTensor([targets[i]])\n",
    "\n",
    "        outputs = torch.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(vocab_size, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 반복:0 오차: 5.675046920776367\n",
      "['\\x1f', '\\r', ',', '\\x9f']\n",
      "\n",
      " 반복:100 오차: 2.0893044471740723\n",
      "['h', 'o', 'l', 'l']\n",
      "\n",
      " 반복:200 오차: 0.6163396239280701\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:300 오차: 0.29440271854400635\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:400 오차: 0.18808504939079285\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:500 오차: 0.1334923803806305\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:600 오차: 0.10067909955978394\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:700 오차: 0.07920406758785248\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:800 오차: 0.0642411857843399\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:900 오차: 0.05330570414662361\n",
      "['h', 'o', 'l', 'a']\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
